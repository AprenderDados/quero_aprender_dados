## ğŸ“˜ Exemplo 6 â€“ Recarga HistÃ³rica com IteraÃ§Ã£o por `modified_date`

Neste exemplo, vamos lidar com **mÃºltiplas versÃµes de um mesmo registro** que chegam em diferentes datas. A ideia Ã© garantir que **todas as alteraÃ§Ãµes sejam aplicadas em ordem cronolÃ³gica**, preservando o histÃ³rico completo usando o padrÃ£o **SCD Type 2**.

---

### ğŸ§  CenÃ¡rio

Em pipelines de produÃ§Ã£o, normalmente lidamos com apenas a versÃ£o mais recente de um dado. No entanto, em situaÃ§Ãµes de:

- ğŸ” Recarga completa
- ğŸ§¼ ManutenÃ§Ã£o de histÃ³rico
- ğŸ”„ Reprocessamento retroativo

...Ã© essencial garantir que todas as **versÃµes intermediÃ¡rias** sejam aplicadas corretamente.

---

### ğŸ¯ EstratÃ©gia Utilizada

1. Obter os valores distintos de `modified_date` da fonte.
2. Iterar sobre cada data, **em ordem cronolÃ³gica**.
3. Para cada `modified_date`:
   - Filtrar os dados daquele dia.
   - Remover duplicatas com `row_number()` para manter o registro mais recente por ID.
   - Aplicar o padrÃ£o SCD2 com `MERGE`.

Essa abordagem permite aplicar alteraÃ§Ãµes **na ordem em que aconteceram**, garantindo a integridade do histÃ³rico.

---

### ğŸ” Diagrama da EstratÃ©gia com Loop

```mermaid
flowchart TD
    Start["Lista de modified_date"] --> Loop
    Loop --> Filtro
    Filtro --> Deduplicacao
    Deduplicacao --> Merge
    Merge --> Loop
    Loop --> End["Todas as versÃµes aplicadas"]
```

---

### ğŸ”¢ Exemplo de Dados com MÃºltiplas VersÃµes

#### ğŸ” Origem (dados da fonte)

| product_id | price | modified_date     | ObservaÃ§Ã£o                          |
|------------|-------|-------------------|-------------------------------------|
| 1          | 10    | 2024-01-01        | Novo                                |
| 2          | 15    | 2024-01-01        | VersÃ£o 1                            |
| 2          | 15    | 2024-01-01        | â›”ï¸ Duplicado (ignorar)              |
| 2          | 16    | 2024-01-02        | VersÃ£o 2                            |
| 2          | 18    | 2024-01-03        | VersÃ£o 3 (final)                    |

#### âœ… Tabela Final Esperada (com histÃ³rico completo)

| product_id | price | modified_date     | valid_from       | valid_to         | is_current |
|------------|-------|-------------------|------------------|------------------|------------|
| 1          | 10    | 2024-01-01        | 2024-01-01       | *(null)*         | âœ… true     |
| 2          | 15    | 2024-01-01        | 2024-01-01       | 2024-01-02       | âŒ false    |
| 2          | 16    | 2024-01-02        | 2024-01-02       | 2024-01-03       | âŒ false    |
| 2          | 18    | 2024-01-03        | 2024-01-03       | *(null)*         | âœ… true     |

---

### ğŸ§ª CÃ³digo PySpark â€“ Loop por `modified_date` com deduplicaÃ§Ã£o

```python
from delta.tables import DeltaTable
from pyspark.sql.window import Window
from pyspark.sql.functions import row_number, col

# Obter lista de datas distintas ordenadas
datas = [row.modified_date for row in df_source.select("modified_date").distinct().orderBy("modified_date").collect()]

target_table = DeltaTable.forName(spark, "target_silver.ex6_sales_orderdetail")

for data in datas:
    print(f"\nğŸ” Processando dados de: {data}")

    dia_df = df_source.filter(col("modified_date") == data)

    # DeduplicaÃ§Ã£o com row_number por chave natural
    window_spec = Window.partitionBy("SalesOrderID", "SalesOrderDetailID").orderBy(col("modified_date").desc())
    dia_df = dia_df.withColumn("row_num", row_number().over(window_spec)).filter("row_num = 1").drop("row_num")
    dia_df.createOrReplaceTempView("source_dia")

    # 1. Finalizar registros antigos
    spark.sql("""
    MERGE INTO target_silver.ex6_sales_orderdetail AS target
    USING source_dia AS source
    ON target.SalesOrderID = source.SalesOrderID AND target.SalesOrderDetailID = source.SalesOrderDetailID
    WHEN MATCHED AND target.hash_value != source.hash_value AND target.is_current = TRUE AND source.modified_date > target.modified_date THEN
      UPDATE SET target.is_current = FALSE,
                 target.end_date = CURRENT_DATE
    """)

    # 2. Inserir nova versÃ£o
    spark.sql("""
    WITH filtered_source AS (
        SELECT source.*
        FROM source_dia AS source
        LEFT JOIN target_silver.ex6_sales_orderdetail AS target
        ON target.SalesOrderID = source.SalesOrderID AND target.SalesOrderDetailID = source.SalesOrderDetailID
        WHERE source.modified_date > target.modified_date OR target.SalesOrderID IS NULL
    )
    MERGE INTO target_silver.ex6_sales_orderdetail AS target
    USING filtered_source AS source
    ON target.SalesOrderID = source.SalesOrderID AND target.SalesOrderDetailID = source.SalesOrderDetailID AND target.hash_value = source.hash_value
    WHEN NOT MATCHED THEN
      INSERT *
    """)
```

---

### âœ… ConclusÃ£o

Neste exemplo, demonstramos como realizar uma **recarga completa e cronolÃ³gica de um histÃ³rico SCD2** usando o campo `modified_date` como guia.

TambÃ©m garantimos que, dentro de cada data, apenas o **registro mais recente por ID** seja utilizado, evitando duplicaÃ§Ãµes e conflitos de `MERGE`.

Essa abordagem Ã© ideal para:

- ğŸ§¹ Pipelines de manutenÃ§Ã£o
- ğŸ” Reprocessamento histÃ³rico
- ğŸ“¦ AplicaÃ§Ã£o de mÃºltiplas versÃµes intermediÃ¡rias

Na prÃ¡tica, garantimos que cada versÃ£o de um mesmo registro seja inserida e encerrada corretamente, mantendo a integridade e rastreabilidade dos dados.

Pronto para avanÃ§ar para o prÃ³ximo desafio? ğŸš€

